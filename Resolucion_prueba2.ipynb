{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Muestra 1</th>\n",
       "      <th>Muestra 2</th>\n",
       "      <th>Muestra 3</th>\n",
       "      <th>Muestra 4</th>\n",
       "      <th>Muestra 5</th>\n",
       "      <th>Muestra 6</th>\n",
       "      <th>Muestra 7</th>\n",
       "      <th>Muestra 8</th>\n",
       "      <th>Muestra 9</th>\n",
       "      <th>Muestra 10</th>\n",
       "      <th>...</th>\n",
       "      <th>Muestra 56</th>\n",
       "      <th>Muestra 57</th>\n",
       "      <th>Muestra 58</th>\n",
       "      <th>Muestra 59</th>\n",
       "      <th>Muestra 60</th>\n",
       "      <th>Muestra 61</th>\n",
       "      <th>Muestra 62</th>\n",
       "      <th>Muestra 63</th>\n",
       "      <th>Muestra 64</th>\n",
       "      <th>resultado</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>26.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-13.0</td>\n",
       "      <td>-109.0</td>\n",
       "      <td>-66.0</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-28.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-7.0</td>\n",
       "      <td>-59.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-47.0</td>\n",
       "      <td>-6.0</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>-7.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>-10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-25.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-19.0</td>\n",
       "      <td>-8.0</td>\n",
       "      <td>-8.0</td>\n",
       "      <td>-8.0</td>\n",
       "      <td>-21.0</td>\n",
       "      <td>-6.0</td>\n",
       "      <td>-79.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-83.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-8.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>114.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>-14.0</td>\n",
       "      <td>-16.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-38.0</td>\n",
       "      <td>-11.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>119.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-14.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>-51.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>38.0</td>\n",
       "      <td>-35.0</td>\n",
       "      <td>-8.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>-13.0</td>\n",
       "      <td>-24.0</td>\n",
       "      <td>-112.0</td>\n",
       "      <td>-69.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>15.0</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>-15.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>-22.0</td>\n",
       "      <td>-38.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-26.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>-48.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-12.0</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-16.0</td>\n",
       "      <td>-17.0</td>\n",
       "      <td>-69.0</td>\n",
       "      <td>-16.0</td>\n",
       "      <td>-12.0</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-36.0</td>\n",
       "      <td>-10.0</td>\n",
       "      <td>-12.0</td>\n",
       "      <td>-16.0</td>\n",
       "      <td>-12.0</td>\n",
       "      <td>-47.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>-30.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7 rows Ã— 65 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Muestra 1  Muestra 2  Muestra 3  Muestra 4  Muestra 5  Muestra 6  \\\n",
       "0       26.0        4.0        5.0        8.0       -1.0      -13.0   \n",
       "1      -47.0       -6.0       -5.0       -7.0       13.0       -1.0   \n",
       "2      -19.0       -8.0       -8.0       -8.0      -21.0       -6.0   \n",
       "3        2.0        3.0        0.0        2.0        0.0       22.0   \n",
       "4        6.0        0.0        0.0       -2.0      -14.0       10.0   \n",
       "5       15.0       -5.0       -5.0      -15.0       12.0      -22.0   \n",
       "6      -12.0       -5.0       -1.0        4.0      -16.0      -17.0   \n",
       "\n",
       "   Muestra 7  Muestra 8  Muestra 9  Muestra 10  ...  Muestra 56  Muestra 57  \\\n",
       "0     -109.0      -66.0       -9.0         2.0  ...       -28.0        61.0   \n",
       "1       35.0      -10.0       10.0        -4.0  ...       -25.0        47.0   \n",
       "2      -79.0       12.0        0.0         5.0  ...       -83.0         7.0   \n",
       "3      106.0      -14.0      -16.0        -2.0  ...       -38.0       -11.0   \n",
       "4      -51.0        5.0        7.0         0.0  ...        38.0       -35.0   \n",
       "5      -38.0       36.0        9.0         6.0  ...       -26.0         5.0   \n",
       "6      -69.0      -16.0      -12.0        -3.0  ...         1.0       -36.0   \n",
       "\n",
       "   Muestra 58  Muestra 59  Muestra 60  Muestra 61  Muestra 62  Muestra 63  \\\n",
       "0         4.0         8.0         5.0         4.0        -7.0       -59.0   \n",
       "1         6.0         6.0         5.0        13.0        21.0       111.0   \n",
       "2         7.0         1.0        -8.0         7.0        21.0       114.0   \n",
       "3         4.0         7.0        11.0        33.0        39.0       119.0   \n",
       "4        -8.0         2.0         6.0       -13.0       -24.0      -112.0   \n",
       "5         6.0         6.0        11.0         5.0        30.0       -48.0   \n",
       "6       -10.0       -12.0       -16.0       -12.0       -47.0         6.0   \n",
       "\n",
       "   Muestra 64  resultado  \n",
       "0        16.0          0  \n",
       "1        15.0          0  \n",
       "2        48.0          0  \n",
       "3        43.0          0  \n",
       "4       -69.0          0  \n",
       "5        25.0          0  \n",
       "6       -30.0          0  \n",
       "\n",
       "[7 rows x 65 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importar librerias\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sb\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "\n",
    "from pandas import Series, DataFrame\n",
    "from pylab import rcParams\n",
    "from sklearn import preprocessing\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics \n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Cargamos el dataset\n",
    "PHT = pd.read_csv(\"dataset-prueba2.csv\")\n",
    "PHT.head(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Descripcion de mi dataset segÃºn mi etiqueta\n",
    "sb.countplot(x=\"resultado\", data=PHT, palette=\"bwr\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardar mi etiqueta en una variable resultY\n",
    "resultY=PHT['resultado']\n",
    "PHT=PHT.drop(['resultado'],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Muestra 1</th>\n",
       "      <th>Muestra 2</th>\n",
       "      <th>Muestra 3</th>\n",
       "      <th>Muestra 4</th>\n",
       "      <th>Muestra 5</th>\n",
       "      <th>Muestra 6</th>\n",
       "      <th>Muestra 7</th>\n",
       "      <th>Muestra 8</th>\n",
       "      <th>Muestra 9</th>\n",
       "      <th>Muestra 10</th>\n",
       "      <th>...</th>\n",
       "      <th>Muestra 55</th>\n",
       "      <th>Muestra 56</th>\n",
       "      <th>Muestra 57</th>\n",
       "      <th>Muestra 58</th>\n",
       "      <th>Muestra 59</th>\n",
       "      <th>Muestra 60</th>\n",
       "      <th>Muestra 61</th>\n",
       "      <th>Muestra 62</th>\n",
       "      <th>Muestra 63</th>\n",
       "      <th>Muestra 64</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>26.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-13.0</td>\n",
       "      <td>-109.0</td>\n",
       "      <td>-66.0</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>21.0</td>\n",
       "      <td>-28.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-7.0</td>\n",
       "      <td>-59.0</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-47.0</td>\n",
       "      <td>-6.0</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>-7.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>-10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-105.0</td>\n",
       "      <td>-25.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows Ã— 64 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Muestra 1  Muestra 2  Muestra 3  Muestra 4  Muestra 5  Muestra 6  \\\n",
       "0       26.0        4.0        5.0        8.0       -1.0      -13.0   \n",
       "1      -47.0       -6.0       -5.0       -7.0       13.0       -1.0   \n",
       "\n",
       "   Muestra 7  Muestra 8  Muestra 9  Muestra 10  ...  Muestra 55  Muestra 56  \\\n",
       "0     -109.0      -66.0       -9.0         2.0  ...        21.0       -28.0   \n",
       "1       35.0      -10.0       10.0        -4.0  ...      -105.0       -25.0   \n",
       "\n",
       "   Muestra 57  Muestra 58  Muestra 59  Muestra 60  Muestra 61  Muestra 62  \\\n",
       "0        61.0         4.0         8.0         5.0         4.0        -7.0   \n",
       "1        47.0         6.0         6.0         5.0        13.0        21.0   \n",
       "\n",
       "   Muestra 63  Muestra 64  \n",
       "0       -59.0        16.0  \n",
       "1       111.0        15.0  \n",
       "\n",
       "[2 rows x 64 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Verificar si se elimino la columna resultado\n",
    "PHT.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#selecciÃ³n de la primera columna de nuestro dataset hasta la columna 65\n",
    "X = PHT.iloc[0:len(PHT),0:65]\n",
    "#selecciÃ³n de la segunda columna de nuestro dataset\n",
    "y = resultY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# En este apartado se divide el dataset a un 30% test. La idea es ir modificando el porcentaje del dataset de entrenamiento-test\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = .3, random_state=25)\n",
    "\n",
    "from sklearn import tree\n",
    "#Entrenamiento\n",
    "clf = tree.DecisionTreeClassifier()\n",
    "clf = clf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[784  14  92]\n",
      " [  6 751  91]\n",
      " [ 68  97 724]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.88      0.90       890\n",
      "           1       0.87      0.89      0.88       848\n",
      "           2       0.80      0.81      0.81       889\n",
      "\n",
      "    accuracy                           0.86      2627\n",
      "   macro avg       0.86      0.86      0.86      2627\n",
      "weighted avg       0.86      0.86      0.86      2627\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Predicciones. Evaluacion del modelo mediante la matriz de confusion\n",
    "y_pred = clf.predict(X_test)\n",
    "#EvaluaciÃ³n del rendimiento del clasificador\n",
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix = confusion_matrix(y_test, y_pred)\n",
    "print(confusion_matrix)\n",
    "#Print de la matriz de confusiÃ³n\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='warn', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##Regresion logistica\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "#Aprendizaje\n",
    "LogReg = LogisticRegression()\n",
    "LogReg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[401 240 249]\n",
      " [112 372 364]\n",
      " [175 340 374]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.45      0.51       890\n",
      "           1       0.39      0.44      0.41       848\n",
      "           2       0.38      0.42      0.40       889\n",
      "\n",
      "    accuracy                           0.44      2627\n",
      "   macro avg       0.45      0.44      0.44      2627\n",
      "weighted avg       0.45      0.44      0.44      2627\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Predicciones\n",
    "y_pred = LogReg.predict(X_test)\n",
    "#EvaluaciÃ³n del rendimiento del clasificador\n",
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix = confusion_matrix(y_test, y_pred)\n",
    "print(confusion_matrix)\n",
    "#Print de la matriz de confusiÃ³n\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1733    3   33]\n",
      " [   1 1628  102]\n",
      " [  77   45 1632]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.98      0.97      1769\n",
      "           1       0.97      0.94      0.96      1731\n",
      "           2       0.92      0.93      0.93      1754\n",
      "\n",
      "    accuracy                           0.95      5254\n",
      "   macro avg       0.95      0.95      0.95      5254\n",
      "weighted avg       0.95      0.95      0.95      5254\n",
      "\n"
     ]
    }
   ],
   "source": [
    "##random forest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=15)\n",
    "clf = clf.fit(X_train, y_train)\n",
    "\n",
    "#Predicciones\n",
    "y_pred = clf.predict(X_test)\n",
    "#EvaluaciÃ³n del rendimiento del clasificador\n",
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix = confusion_matrix(y_test, y_pred)\n",
    "print(confusion_matrix)\n",
    "#Print de la matriz de confusiÃ³n\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# En este apartado se divide el dataset a un 40% test. La idea es ir modificando el porcentaje del dataset de entrenamiento-test\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = .4, random_state=25)\n",
    "\n",
    "from sklearn import tree\n",
    "#Entrenamiento\n",
    "clf = tree.DecisionTreeClassifier()\n",
    "clf = clf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1042   13  122]\n",
      " [  13 1036   96]\n",
      " [  97  139  945]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.89      0.89      1177\n",
      "           1       0.87      0.90      0.89      1145\n",
      "           2       0.81      0.80      0.81      1181\n",
      "\n",
      "    accuracy                           0.86      3503\n",
      "   macro avg       0.86      0.86      0.86      3503\n",
      "weighted avg       0.86      0.86      0.86      3503\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Predicciones\n",
    "y_pred = clf.predict(X_test)\n",
    "#EvaluaciÃ³n del rendimiento del clasificador\n",
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix = confusion_matrix(y_test, y_pred)\n",
    "print(confusion_matrix)\n",
    "#Print de la matriz de confusiÃ³n\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='warn', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##Regresion logistica\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "#Aprendizaje\n",
    "LogReg = LogisticRegression()\n",
    "LogReg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[534 298 345]\n",
      " [176 483 486]\n",
      " [264 411 506]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.45      0.50      1177\n",
      "           1       0.41      0.42      0.41      1145\n",
      "           2       0.38      0.43      0.40      1181\n",
      "\n",
      "    accuracy                           0.43      3503\n",
      "   macro avg       0.44      0.43      0.44      3503\n",
      "weighted avg       0.44      0.43      0.44      3503\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Predicciones\n",
    "y_pred = LogReg.predict(X_test)\n",
    "#EvaluaciÃ³n del rendimiento del clasificador\n",
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix = confusion_matrix(y_test, y_pred)\n",
    "print(confusion_matrix)\n",
    "#Print de la matriz de confusiÃ³n\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1155    4   18]\n",
      " [   1 1076   68]\n",
      " [  39   27 1115]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.98      0.97      1177\n",
      "           1       0.97      0.94      0.96      1145\n",
      "           2       0.93      0.94      0.94      1181\n",
      "\n",
      "    accuracy                           0.96      3503\n",
      "   macro avg       0.96      0.96      0.96      3503\n",
      "weighted avg       0.96      0.96      0.96      3503\n",
      "\n"
     ]
    }
   ],
   "source": [
    "##random forest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=15)\n",
    "clf = clf.fit(X_train, y_train)\n",
    "\n",
    "#Predicciones\n",
    "y_pred = clf.predict(X_test)\n",
    "#EvaluaciÃ³n del rendimiento del clasificador\n",
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix = confusion_matrix(y_test, y_pred)\n",
    "print(confusion_matrix)\n",
    "#Print de la matriz de confusiÃ³n\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# En este apartado se divide el dataset a un 60% test. La idea es ir modificando el porcentaje del dataset de entrenamiento-test\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = .6, random_state=25)\n",
    "\n",
    "from sklearn import tree\n",
    "#Entrenamiento\n",
    "clf = tree.DecisionTreeClassifier()\n",
    "clf = clf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1562   16  191]\n",
      " [   4 1537  190]\n",
      " [ 140  191 1423]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.88      0.90      1769\n",
      "           1       0.88      0.89      0.88      1731\n",
      "           2       0.79      0.81      0.80      1754\n",
      "\n",
      "    accuracy                           0.86      5254\n",
      "   macro avg       0.86      0.86      0.86      5254\n",
      "weighted avg       0.86      0.86      0.86      5254\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Predicciones\n",
    "y_pred = clf.predict(X_test)\n",
    "#EvaluaciÃ³n del rendimiento del clasificador\n",
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix = confusion_matrix(y_test, y_pred)\n",
    "print(confusion_matrix)\n",
    "#Print de la matriz de confusiÃ³n\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
